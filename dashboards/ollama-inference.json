{
  "dashboard": {
    "id": null,
    "uid": "ollama-inference",
    "title": "Ollama Inference Speed",
    "tags": [
      "ollama",
      "inference",
      "telemetry"
    ],
    "timezone": "browser",
    "refresh": "10s",
    "time": {
      "from": "now-1h",
      "to": "now"
    },
    "panels": [
      {
        "id": 1,
        "title": "Tokens/Second Over Time",
        "type": "timeseries",
        "gridPos": {
          "h": 8,
          "w": 12,
          "x": 0,
          "y": 0
        },
        "targets": [
          {
            "expr": "ollama_tokens_per_second",
            "legendFormat": "{{model}}",
            "refId": "A"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "unit": "tok/s",
            "color": {
              "mode": "palette-classic"
            }
          }
        }
      },
      {
        "id": 2,
        "title": "Model Load Time",
        "type": "gauge",
        "gridPos": {
          "h": 8,
          "w": 6,
          "x": 12,
          "y": 0
        },
        "targets": [
          {
            "expr": "ollama_model_load_seconds",
            "legendFormat": "{{model}}",
            "refId": "A"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "unit": "s",
            "thresholds": {
              "steps": [
                {
                  "value": 0,
                  "color": "green"
                },
                {
                  "value": 5,
                  "color": "yellow"
                },
                {
                  "value": 15,
                  "color": "red"
                }
              ]
            }
          }
        }
      },
      {
        "id": 3,
        "title": "Prompt Eval Rate",
        "type": "stat",
        "gridPos": {
          "h": 8,
          "w": 6,
          "x": 18,
          "y": 0
        },
        "targets": [
          {
            "expr": "rate(ollama_prompt_eval_count[5m])",
            "legendFormat": "eval/s",
            "refId": "A"
          }
        ]
      },
      {
        "id": 4,
        "title": "Inference Requests",
        "type": "timeseries",
        "gridPos": {
          "h": 8,
          "w": 24,
          "x": 0,
          "y": 8
        },
        "targets": [
          {
            "expr": "rate(ollama_request_total[5m])",
            "legendFormat": "{{status}}",
            "refId": "A"
          }
        ]
      },
      {
        "id": 5,
        "title": "Active Model Memory",
        "type": "bargauge",
        "gridPos": {
          "h": 8,
          "w": 12,
          "x": 0,
          "y": 16
        },
        "targets": [
          {
            "expr": "ollama_model_memory_bytes",
            "legendFormat": "{{model}}",
            "refId": "A"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "unit": "bytes"
          }
        }
      },
      {
        "id": 6,
        "title": "Thread Utilization",
        "type": "gauge",
        "gridPos": {
          "h": 8,
          "w": 12,
          "x": 12,
          "y": 16
        },
        "targets": [
          {
            "expr": "ollama_num_threads",
            "legendFormat": "threads",
            "refId": "A"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "max": 4,
            "thresholds": {
              "steps": [
                {
                  "value": 0,
                  "color": "green"
                },
                {
                  "value": 3,
                  "color": "yellow"
                },
                {
                  "value": 4,
                  "color": "red"
                }
              ]
            }
          }
        }
      }
    ]
  }
}